%%% SETUP %%%
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{titling}
\usepackage{setspace}
\usepackage{hyperref}
\setcounter{secnumdepth}{0} %Table of contents without numbers

\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    \vskip0.5em}%
}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
}

%%%%% /SETUP %%%%%
%%%%% Title page %%%%%
\title{Proof of Concept - Elaboration}
\subtitle{FOAR705 2019}
\author{Matthew Clark\\43695841}
\date{\vspace{-5ex}} %Used to remove date when using \maketitle%
\begin{document}
\doublespacing
\maketitle
%%%%% /Title Page %%%%%
%%%%% Table of Contents %%%%%
\newpage
\tableofcontents
%%%%% /Table of Contents %%%%%
%%%%% Entry 1 %%%%%
\newpage
\section{Elaboration I}
\subsection{Scope}
Before I begin in discussing the various technologies that could be used in my project, I have decided to narrow the scope for this research project such that I can focus more intently on it. Hence, my project will be focusing purely on using an API to gather a data set. More specifically, my scope includes:
\begin{enumerate}
    \item Identifying the scope of the data I want to collect. Because this is dependent on the specific API I use, this will be identified as I gain access to a specific API.
    \item Identifying what API I want to use.
    \item Developing a script in some language in order to access the API and gather the data based on the API's documentation
    \item Convert the retrieved data and parse it in order to import it into a spreadsheet
    \item Copy the spreadsheet and clean up the data
\end{enumerate}
\subsection{Technologies}
First technology I am aiming to use is Beatport's API, as it is the most popular charting \& online store for modern electronic music. The API uses OAUTH1.0 and the API can be accessed through Python, which can retrieved data by JSON strings. All the API commands and documentation are available on its API website:\\\url{https://oauth-api.beatport.com/}\\This means I can develop a script to gather the data required and import it into excel using its data import function.

\subsection{Alternative Strategies:}
As the Beatport API requires being able to get an API Key, which I must request directly from Beatport, if I am unable to get a key, I need to think of alternative strategies.
\begin{enumerate}
    \item The first strategy is to use web scraping using archived Beatport pages. This will be trickier, as I will need to import web pages through the internet wayward machine, and extract the data using developed Python scripts, but this is a viable alternative.
    \item The second strategy is to use an alternative API to Beatport:
    \begin{enumerate}
        \item The issue with using something such as the Spotify API is that Spotify doesn't classify anything lower then \textit{Electronic}, so specifically getting Techno music will mean using Spotify will be redundant, including other services similar to it.
        \item A site such as Discogs, which has an accessible API, is a possibility, and they do categorise songs by sub-genre. The problem is each song's genre is tied to all the song's genre classifications, meaning a song can be classified as Techno if it has some similarities to the genre, while not really representing the genre. For example, a song could be classified as \textit{house, techno, dub techno, soul, breakbeat, leftfield}, and hence using the API will require me to focus on songs with the techno genre tag, while also removing songs which have any other associated genre tag. Discogs also categorise songs by their release format rather than by songs, so pulling data will also include pulling in albums worth of songs, rather than individual tracks. Lastly, discogs can filter songs by popularity, rather than by sales, so, for example, I will have to gather songs based on 'Most owned' or 'Most wanted' rather than 'Most purchased'.
        \item Another API alternative is Traxsource, which is similar to Beatport, however it doesn't have a general API, but instead there is an API created in the Ruby language, developed using Heroku and MongoDB, which means learning 3 different forms of software and getting them all to talk to one another successfully, which may cause some issues. The documentation is also very sparse, so being able to extract bulk data may not even be possible. 
    \end{enumerate}
    \item The last strategy is web scraping from various online magazines, blogs, and forums. While there are many 'Top x songs from the year xxxx' lists floating around, cataloguing them all and defining a specific scope for my data will be a lot harder, while also being more time consuming, but is not an unviable alternative at this stage.  
\end{enumerate}
%%%%%
\section{Elaboration II}
%%%%%
\subsection{Beatport API}
\textbf{Overview:}
\begin{itemize}
    \item \textbf{Online Since:}
    \item \textbf{Popularity}
    \item \textbf{Wikipedia Summary:}
    \item \textbf{Website Link:}
    \item \textbf{API Link:}
    \item \textbf{Documentation:}
    \item \textbf{Languages:}
\end{itemize}
\textbf{Steps for Success:}
\textbf{Reason for Failure:}
\textbf{Alternative Routes using Beatport}\\
Web Scraping using Internet Archive. Not elaborated due to scope and time intensity.

\subsection{Traxsource API}
\textbf{Overview:}
\begin{itemize}
    \item \textbf{Online Since:}
    \item \textbf{Popularity}
    \item \textbf{Wikipedia Summary:}
    \item \textbf{Website Link:}
    \item \textbf{API Link:}
    \item \textbf{Documentation:}
    \item \textbf{Languages:}
\end{itemize}
\textbf{Steps for Success:}
\textbf{Reason for Failure:}
\textbf{Alternative Routes using Traxsource}

\subsection{Discogs API}
\textbf{Overview:}
\begin{itemize}
    \item \textbf{Online Since:}
    \item \textbf{Popularity}
    \item \textbf{Wikipedia Summary:}
    \item \textbf{Website Link:}
    \item \textbf{API Link:}
    \item \textbf{Documentation:}
    \item \textbf{Languages:}
\end{itemize}
\textbf{Steps for Success:}
\textbf{Potential Pitfalls & Alternative Routes:}





\end{document}
